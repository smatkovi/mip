{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floppy-processing",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c31ae328995f884cd65b5e7a4e6ae231",
     "grade": false,
     "grade_id": "cell-d872eb957eb1f9a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Exercise 2: Advanced Gradient Descent\n",
    "-------------------------------------\n",
    "\n",
    "Before we start modifying our gradient descent algorithm, let us first\n",
    "put it in a more \"useful\" form.  Remember from the lecture on higher-order\n",
    "functions that we can pass any function `f` as parameter into another\n",
    "function and then just call the passed function.\n",
    "\n",
    "Copy your function `gradient_descent()` from the previous lecture and\n",
    "modify it such that it takes an additional parameter: `grad` (which is\n",
    "a function returning the gradient).\n",
    "\n",
    "You can remove any `print()` statements from the function \n",
    "(we will do this in a better way soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-biotechnology",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f99f0896ea5c55592c7d5e3ed81e4cf",
     "grade": true,
     "grade_id": "cell-76b97c158d0e2478",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(grad, x0, eta, max_iter):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-virgin",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dbab494c55136c971ed7cd78fcb9b6a",
     "grade": false,
     "grade_id": "cell-a3d607832ec162a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we have a truly useful gradient descent function, which works for\n",
    "any 1D function we throw at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mexican_hat(x):\n",
    "    return x**4 - 2 * x**2\n",
    "    \n",
    "def mexican_hat_grad(x):\n",
    "    return 4 * (x**3 - x)\n",
    "\n",
    "xmin = gradient_descent(mexican_hat_grad, -1.5, 0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f(\", xmin, \") =\", mexican_hat(xmin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-principle",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73d42198f4c3ed79cef34caef9c790b7",
     "grade": false,
     "grade_id": "cell-b23fec1743324168",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Try this out!  Make up some potential with a minimum, define its derivative,\n",
    "see if your `gradient_descent` function can handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-macedonia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-geometry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-breach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "massive-excuse",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "673dabce12f23ce4de95d83d2a17a96e",
     "grade": false,
     "grade_id": "cell-0c3f012adba94751",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lists and plotting\n",
    "---------------------\n",
    "\n",
    "Let's understand graphically how the `mexican_hat` function looks.  To\n",
    "do this, let us first create two lists, either by appending elements in a loop or\n",
    "by list comprehension:\n",
    "\n",
    "  - a list `x` with values from `[-1.5, -1.4, ..., 1.5]`\n",
    "  - a list `y` with the associated values of `mexican_hat` for each of the `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-london",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b660cde3d5b6d39982bc4acc17e4d9b",
     "grade": false,
     "grade_id": "cell-c03e419e7aad0621",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# x = ...\n",
    "# y = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-lodging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-torture",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c355dd914760e73bd53af5442a4a8c96",
     "grade": true,
     "grade_id": "cell-f2c0a4fc2cf428cf",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(x) == len(y), \"Arrays x and y should be of the same length\"\n",
    "assert abs(x[0] + 1.5) < 1e-10, \"First value of x should be -1.5\"\n",
    "assert abs(x[-1] - 1.5) < 1e-10, \"Last value of x should be 1.5\"\n",
    "assert abs(y[0] - mexican_hat(-1.5)) < 1e-5, \"y values do not match x\"\n",
    "assert abs(y[-1] - mexican_hat(1.5)) < 1e-5, \"y values do not match x\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-conclusion",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb29b3162571b5ffc473ab24d5d9c4a4",
     "grade": false,
     "grade_id": "cell-db2b8773bd797dd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's plot this now: plot the values `y` over `x` using matplotlib. Don't forget to import the library.\n",
    "\n",
    "Remember for this and all subsequent plots: \n",
    " - include a title\n",
    " - include axis labels\n",
    " - if you plot more than one function in a single figure, use labels and a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-extra",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bca3604f7984174ae6f2d1ed4a5565a",
     "grade": true,
     "grade_id": "cell-da92b63354cbdd2b",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-diana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-armstrong",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27cd453334a4d6faa1acab777cd8364d",
     "grade": false,
     "grade_id": "cell-e460688a9fb3b525",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we would like to understand how gradient descent converges to one of the minima shown above.\n",
    "\n",
    "For this, copy the function from above and give it the new name `gradient_descent_all`.\n",
    "Modify the function from its original as follows: instead of only the `x` value for the last\n",
    "iteration it should give a list of values corresponding to `x` in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-analysis",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6340259a4b271a3e2b92acc9f69dd0fd",
     "grade": false,
     "grade_id": "cell-968a25802446fc1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent_all(grad, x0, eta, max_iter):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent_all(mexican_hat_grad, 1.5, 0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-effort",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c331e0aba401b2bd36e338cba44ec71",
     "grade": true,
     "grade_id": "cell-19bb6a0f59d85726",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert iter(gradient_descent_all(mexican_hat_grad, 1.5, 0.1, 20)), \"should give list\"\n",
    "assert abs(gradient_descent_all(mexican_hat_grad, 1.77, 0.1, 20)[0] - 1.77) < 1e-5, \"initial value missing\"\n",
    "assert abs(gradient_descent_all(mexican_hat_grad, 1.5, 0.1, 20)[-1] - 1) < 1e-5, \"last value should converge\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-basketball",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c320b1fa03143a3ac0a96d2a1886dac3",
     "grade": false,
     "grade_id": "cell-0e2b6967d6a9fe5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now you can plot this list over the iteration number `t` to see how it converges.\n",
    "Make two figures, each figure with three or so plot lines: one where you vary `eta` and keep the\n",
    "initial position constant and one where you vary the initial position but keep\n",
    "`eta` constant\n",
    "\n",
    "(Hint: look into the documentation of plot to make your life easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-telescope",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47b0262e82089c4c75f01c4f27317cb8",
     "grade": true,
     "grade_id": "cell-ed56b99d9b0fb926",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-regression",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9805a3d9ae8f3c2b51b07d2afb8b1169",
     "grade": true,
     "grade_id": "cell-84ec0aae31489e2e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-transportation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-italian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "technical-auckland",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4636337e2fffa495e05064bc72cfee12",
     "grade": false,
     "grade_id": "cell-bfbe2aef7d0c554d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Nesterov-accelerated Gradient Descent\n",
    "-----------------------------------------------\n",
    "Finally, let's explore the effect of momentum on gradient descent.\n",
    "\n",
    "Copy your function `gradient_descent_all`, and give it a new name\n",
    "`nesterov_all`.  Modify the function to implement the Nesterov acceleration scheme.  You\n",
    "now need the additional mixing parameter `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-prototype",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8e1bd910bc40dde94bdfeb7728415c4",
     "grade": false,
     "grade_id": "cell-6b7b0adc9b96bf67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def nesterov_all(grad, x0, eta, gamma, max_iter):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nesterov_all(mexican_hat_grad, 2.0, 0.1, 0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-export",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e532880d54a0aba474e7f952c8565666",
     "grade": true,
     "grade_id": "cell-29fa70b257d285c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "assert iter(nesterov_all(mexican_hat_grad, 1.5, 0.1, 0.1, 20)), \"should give list\"\n",
    "assert abs(nesterov_all(mexican_hat_grad, 1.77, 0.1, 0.1, 20)[0] - 1.77) < 1e-5, \"initial value missing\"\n",
    "assert abs(nesterov_all(mexican_hat_grad, 1.5, 0.1, 0.1, 20)[-1] - 1) < 1e-5, \"last value should converge\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-binary",
   "metadata": {},
   "source": [
    "Let's compare how Nesterov and regular GD converge: Make a figure with two plots: one where you plot the steps for regular gradient descent and one where you plot the steps for Nesterov acceleration for the `mexican_hat` function and the same starting point.\n",
    "\n",
    "Play around a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-laptop",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bca4980373792e5eaaf637ede01fb010",
     "grade": true,
     "grade_id": "cell-861934d7365ab5f6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-class",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d614d84a260a846125bae6a74effcd9",
     "grade": false,
     "grade_id": "cell-5782a2131c9fd129",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Describe in words how the behaviour changes when momentum is included.\n",
    "\n",
    "What happens when you vary `eta`? What happens when you vary `gamma`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-suffering",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ecb7328449596ef05012afa1ff585f7",
     "grade": true,
     "grade_id": "cell-06be6c816ec8ba1b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-usage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c551047f",
   "metadata": {},
   "source": [
    "Back-propagation\n",
    "--------------------------\n",
    "For a super-advanced final touch, let us briefly touch on back-propagation: for this, remember that it allows to compute the derivative of some composition of functions:\n",
    "$$\n",
    "        E(x) = f(g(x))\n",
    "$$\n",
    "by using the chain rule.\n",
    "\n",
    "Let's try this out: write a function that takes as arguments four other functions, representing $f$, $g$ and the derivatives $f'$ and $g'$ and **return a new function** which computes $E'(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbbfb15",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "893b13b46b1e1ddd5a30333c304a7cc7",
     "grade": false,
     "grade_id": "cell-93ca4970f36436ae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_back_prop(f, g, gradf, gradg):\n",
    "    def gradfg(x):\n",
    "        # Here you should use f, g, gradf, and/or gradg to compute E'(x)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    # This returns the function we have constructed above.  In other words,\n",
    "    # get_back_prop is a function that combines functions to a new function.\n",
    "    # (Cue horn sounds from the movie Inception.)\n",
    "    return gradfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d55780",
   "metadata": {},
   "source": [
    "Let's try out your function:\n",
    "\n",
    "I have assumed that $E(x) =$ `mexican_hat(linear_trafo(x))`, in other words,\n",
    "$f(x) =$ `mexican_hat(x)` and $g(x) =$ `linear_trafo(x)`.  This is common in\n",
    "Machine Learning, where a linear and a non-linear part alternates.  Let's see\n",
    "if we can apply back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc66992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_trafo(x):\n",
    "    return 2 * x + 1\n",
    "\n",
    "def linear_trafo_grad(x):\n",
    "    return 2\n",
    "\n",
    "def E(x):\n",
    "    return mexican_hat(linear_trafo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dEdx = get_back_prop(mexican_hat, linear_trafo, mexican_hat_grad, linear_trafo_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70433f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "017655b38a08102c8f66457ef69678ef",
     "grade": true,
     "grade_id": "cell-cb4666d599f30d6c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert abs(dEdx(0)) < 1e-5, \"dEdx(0) should be zero\"\n",
    "assert abs(dEdx(-1)) < 1e-5, \"dEdx(-1) should be zero\"\n",
    "\n",
    "assert abs(dEdx(0.5) - 48) < 1e-5, \"dEdx(0.5) should be 48 (really? yes!)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa04bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
